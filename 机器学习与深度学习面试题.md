Part0 关于面试
简历上写的一个字都用弄明白，尊重你在简历上写的每一个字，靠谱的公司的面试官也只会围绕简历问，如果不是，要么面试官水平不行要么公司业务不行，这种公司也不要去
面试会就会，不会就不会，可以和面试官交流，记下问题回去研究一下，结果出来之前不要放弃
针对不同岗位做不同的简历：如算法、NLP/CV、数据挖掘，项目经历展现不同侧重点
不可能什么都懂，但是懂得一定要想办法在面试的时候讲出来，不要让面试官猜你会什么东西
Part1 特征工程
归一化和标准化相关概念，有什么作用，几种不同归一化的公式
特征工程
filter：方差选择、相关系数、卡方检验、互信息
wrapper: 递归消除特征
embedded：L1筛选特征的原理（L1和L2的区别，对抗过拟合原理）、树模型进行特征筛选
文本表示：TF-IDF、LDA、word2vector原理（做NLP的要了解Elmo、Transformer、BERT相关）
特征缺失时处理 方法
Part2 模型评估
准确率和召回率
P-R曲线
ROC曲线、AUC面积
P-R曲线和ROC曲线的区别
模型检验方法：holdout、k-fold、bootstrap（公式推导）
参数调优：网格搜索、随机搜索、贝叶斯优化
欠拟合、过拟合：概念、如何避免（这个一定要好好研究，一定会问）
这个部分很基础，但是如果面试官经验丰富，完全可以把你问崩溃，而且这些概念一定会在面试中出现，所以务必重视

Part3 经典算法
SVM：公式推导、对偶和KKT的理解、优劣势
LR：公式推导，和SVM的区别
决策树：
ID3：最大信息增益公式，举例说明
C4.5：最大信息增益率公式（最终信息划分选择），和ID3区别，举例说明
CART：基尼指数公式、回归树步骤，三种树的区别
预剪枝和后剪枝：概念和作用
Part4 集成学习
随机森林：随机性、特点、参数
Adaboost：步骤、特点
GBDT：特点，推导过程
Xgboost：和GBDT的区别、特点
把GBDT和Xgboost好好研究一番

Part5 主题模型
1.pLSA

LDA：概念、原理
Part6 优化方法
平方差损失：概念、梯度下降公式推导
凸函数：概念
梯度下降
牛顿法
正则化和稀疏性：这和问题一定要搞透彻
Part7 深度学习
CNN
RNN
Attention：self-attention
（以上三点的基本内容一定要熟悉，做CV就好好理解CNN，包括BP推导，做NLP就好好理解LSTM和Transformer）
dropout、BN、优化器选择等等trick
深度学习调参方法和步骤