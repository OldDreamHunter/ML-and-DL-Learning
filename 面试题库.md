1、    针对机器学习中的分类任务，常用的模型评价指标是Accuracy、Precision、Recall、F1、AUC，请简述下各个评价指标的应用场景以及在场景中的优劣性？

* Accuracy

  Accuracy是最基本的评价指标，但是针对二分类并且正负样例不平衡，并且我们重点评价数量小的类别，Accuracy就没有参考价值，例如癌症检测，欺诈检测等。

* Recall，Precision，F1-Score

  Recall是测试集中正例被模型预测结果覆盖的情况，Precision是从模型预测为正的结果中，真实也为正的比例。只评价我们感兴趣的类别的Recall和Precision（例如label等于1）。

  如果模型很贪婪，希望覆盖的样本多，那么模型的Recall很高，但是Precision会很低；

  如果模型很保守，只对它确定的样本作出预测，那么模型的Precision很高，但是模型的Recall就会很低；

  F1是综合考虑Precision和Recall的指标，用二者的调和平均。1/F1score = 1/2*(1/recall + 1/precision)

* AUC（Area Under Curve）

  在分类问题的评价中，通常有两个常用的Curve，一个是PR曲线（Precision-Recall），一个是ROC曲线（receiver-operating-characteristic Curve **接收者操作特征曲线**），我们常说的AUC就是Area Under ROC curve。ROC以TPR和FPR为轴，根据不同的threshold的值画的曲线。

  TPR = TP/(TP+FN)，预测为正的样本中，预测正确的比例，就是召回率

  FPR = FP/(FP+TN)，预测为负的样本中，预测错误的比例

  

2、    请问你在机器学习的项目中是否遇到过overfitting的问题？你是如何解决上述情况的？理论上是否还存在其他的方法可以解决上述问题？

* overfitting即模型在训练集上表现好，但在测试集上表现不好

* 解决方法：

  * 增加训练数据； 提前终止；正则化；
  * 借鉴Random Forest中bootstrap采样之后训练多个不同的模型，对模型进行融合；
  * 深度学习中还有dropout和数据增强；

  

3、    在机器学习的分类任务中，大部分分类任务都存在训练样本不均衡的问题，请问有哪些方法可以解决训练样本不均衡的问题？这些方法各有什么优缺点？

* 采样。过采样（oversample） 和 降采样（undersample），oversample是对样本少的类的数据随机多采样（或者加随机噪声采样），undersample是对样本多的类随机少采样。过采样容易造成过拟合（SMOTE算法可以避免），降采样又有可能丢失重要信息（Informed Undersampling）。
* 设置权重。对于样本少的类设置更高的权重
* 评价方法。用AUC或者F1-score进行评价

 

4、    在机器学习中，特征工程部分对项目起着至关重要的作用，如何分析判断特征对于模型的有效性？举例说明。

* feature importance，例如训练一个模型输出各特征的feature importance
* wrapper，例如去除某个特征之后，看剩余特征训练的模型表现
* 和特征相关性，分析特征和标签之间的相关系数

三种方法综合使用，把结果融合起来考虑



5、    讲一下GBDT的细节，写出GBDT的目标函数。 GBDT和Adaboost的区别与联系

* GBDT的算法细节和目标函数

  GBDT的主要思想是构造一组弱分类器，每个弱分类学习目标是上一个弱分类器的残差，最终将多个弱分类器的结果加起来

  GBDT主要是三个方面，GB，DT，Shrinkage，其中DT是用的CART树中的回归树，GB就是损失函数在函数空间的梯度(残差)，shrinkage类似于神经网络中的学习率，在梯度方向上下降的慢一些，更容易收敛

  GBDT目标函数，如果是MSE，则损失函数的梯度正好是残差

* 与adaboost的区别和联系

  联系：都是boost方法，下一次的弱分类器的任务都与上一次的有关，并且都是加法模型

  区别：主要是boost的方式，adaboost的思想是把本轮分错的样本的权重提高，在下一轮学习的时候重点学习上一个分类器分错的样本。涉及到两个权重的更新，一个是样本权重的更新，一个是分类器权重的更新。GBDT的boost是不断学习上一个学习器的残差
  
  

6、 XGBoost作为经典的集成树模型，它是如何寻找最佳分割点？对于缺失值，它是如何如何处理缺失值的？

* 基本查找分割点的算法。

 

7、    LightGBM作为XGBoost的改进版本，它们有什么区别？

* 





8、    特征选择在机器学习起着非常重要的作用，常用的特征选择有哪几种方法？各有什么优缺点？

 

9、    基于每日用户搜索内容，假设只有少量已知商品的情况下，如何根据用户搜索内容获取平台内没有的新商品？

 

10、  为什么logistic回归的要用sigmoid函数？优缺点？

 

11、  常见的正则化有什么，有什么作用，为什么l1是会把feature压缩到0而l2做不到？其他防止过拟合的方法有？（和题目2类似）

 

12、  分类模型如何选择？如何判断效果？如何计算AUC？你最熟悉的集成分类模型是什么？请简述其原理？

 

13、  SVM中用到了哪些核？SVM中的优化技术有哪些？

 

14、  SVM如何学习超平面？用数学方法详细解释一下。

 

15、  讲一下PCA的步骤。PCA和SVD的区别和联系

 

16、  介绍一下无监督学习，算法有哪些？

 

17、  如何部署机器学习模型？

 

18、  简述word2vec的原理，

 



19、  word2vec为什么 不用现成的DNN模型，要继续优化出新方法呢？有哪些方法可以优化word2vec训练时间？



 

20、  word2vec和glove相比有什么优缺点？



 

21、  LSTM中每个 gate 的作用是什么，为什么跟 RNN 比起来，LSTM 可以防止梯度消失？





 

22、  pooling 的作用是什么，为什么 max pooling 更常用？什么情况下 average pooling 更合适？

* 位移不变性；减少计算量；提升感受野的大小；
* 通常max pooling采样效果更好，max pooling能提取出辨识度更好的特征
* average pooling通常在最后一层或者是末端，代替flatten，使得输入数据变成一维向量

 

23、  梯度消失和梯度爆炸的原因是什么，有哪些解决方法？

* 梯度消失的原因一般是选择了不合适的损失函数，例如sigmoid；
* 梯度爆炸的原因一般是初始化权值太大的时候；
* 解决办法是：1.  梯度剪切（限制梯度的范围）和正则化（有效控制梯度爆炸）；2. 改变激活函数(relu，leaky relu)；3. batch normalization

 

24、  CNN 和 RNN 的梯度消失是一样的吗？

* CNN和RNN的梯度消失都是由于层数过深导致，CNN网络层数过深，RNN是时间迭代计算太长

 

25、  CNN、RNN以及transformer在提取特征时的优缺点？

* CNN
  * 优点：可以并行
  * 缺点：无法捕捉长距离的特征，因此提出了两种解决办法，一个是Dilated CNN，间隔卷积；一个是深层CNN，靠深度捕捉特征；输入定长，不够的用padding补充
* RNN
  * 优点：捕捉长距离的特征，可以接受不定长的输入
  * 缺点：大规模并行的问题，改进是用隐藏层之间并行

26、  介绍 sigmoid，tanh，relu 各自的有点和适用场景

为什么要使用非线性激活函数？如果不使用激活函数，这种情况下每一层输出都是上一层输入的线性函数。无论神经网络有多少层，输出都是输入的线性函数，这样就和只有一个隐藏层的效果是一样的。

* tanh
  * 优点：零均值；压缩数据；幂运算耗时
  * 缺点：梯度消失；幂运算耗时
* sigmoid
  * 优点：便于求导；能压缩数据，保证数据幅度不会又问题；适合于前向传播；
  * 缺点：容易出现梯度消失的现象；非0均值导致后续的前向传播会出现偏向；幂运算耗时
* relu
  * 优点：收敛更快，解决梯度消失问题；计算复杂度低；适合反向传播
  * 缺点：输出不是0均值；神经元坏死现象 

27、  relu 的负半轴导数都是 0，这部分产生的梯度消失怎么办？

* relu如果中间某层由于学习率或者导数过大，导致更新w之后，前向传播结果进入了负半区，那这个神经元会出现死亡的现象。
* 改进：LReLu, PReLu, ELU等，其中LReLu/PReLu都是在负半区也设置一个对应的激活函数$αx$，其中LReLu是固定的$α$值，一般取数比较小，PReLu能动态调整负半轴斜率$α$值

 

28、  batch size 对收敛速度的影响

* batch size小，收敛变慢，不容易收敛，极端batch size=1，就是普通的随机梯度下降

* batch size增大，充分利用内存，学习速率变快，收敛速度会加快

* batch size再增大，极端情况batch size=数据集大小，则导致需要学习多个epoch才能达到好的效果

  反而降低了收敛速度



29、  **介绍 batch normalization**

* 因为深层神经网络在做非线性变换前的激活输入值（就是那个x=WU+B，U是输入）随着网络深度加深或者在训练过程中，其分布逐渐发生偏移或者变动，之所以训练收敛慢，一般是整体分布逐渐往非线性函数的取值区间的上下限两端靠近（对于Sigmoid函数来说，意味着激活输入值WU+B是大的负值或正值），所以这导致反向传播时低层神经网络的梯度消失，这是训练深层神经网络收敛越来越慢的本质原因，而BN就是通过一定的规范化手段，把每层神经网络任意神经元这个输入值的分布强行拉回到均值为0方差为1的标准正态分布，其实就是把越来越偏的分布强制拉回比较标准的分布，这样使得激活输入值落在非线性函数对输入比较敏感的区域，这样输入的小变化就会导致损失函数较大的变化，意思是这样让梯度变大，避免梯度消失问题产生，而且梯度变大意味着学习收敛速度快，能大大加快训练速度。

 

30、  如何理解 Dropout？分别从 bagging 和正则化的角度

* Dropout的工作流程：

  * 首先随机（临时）删掉网络中一半的隐藏神经元，输入输出神经元保持不变；
  * 然后把输入x通过修改后的网络前向传播，然后把得到的损失结果通过修改的网络反向传播。一小批训练样本执行完这个过程后，在没有被删除的神经元上按照随机梯度下降法更新对应的参数(w,b)；
  * 然后继续重复这一过程:
    - 恢复被删掉的神经元（此时被删除的神经元保持原样，而没有被删除的神经元已经有所更新）
    - 从隐藏层神经元中随机选择一个一半大小的子集临时删除掉（备份被删除神经元的参数）
    - 对一小批训练样本，先前向传播然后反向传播损失并根据随机梯度下降法更新参数（w，b） （没有被删除的那一部分参数得到更新，删除的神经元参数保持被删除前的结果）
  * 预测的时候需要给每个神经元的输出乘以概率P

* 从bagging和正则化角度

  bagging是boostrap之后训练多个模型，再把模型预测结果取平均；

  正则化包括L1和L2正则化，L1正则化使得w变稀疏，L2正则化使得w变小；

  * **（1）取平均的作用：** 先回到标准的模型即没有dropout，我们用相同的训练数据去训练5个不同的神经网络，一般会得到5个不同的结果，此时我们可以采用 “5个结果取均值”或者“多数取胜的投票策略”去决定最终结果。例如3个网络判断结果为数字9,那么很有可能真正的结果就是数字9，其它两个网络给出了错误结果。这种“综合起来取平均”的策略通常可以有效防止过拟合问题。因为不同的网络可能产生不同的过拟合，取平均则有可能让一些“相反的”拟合互相抵消。dropout掉不同的隐藏神经元就类似在训练不同的网络，随机删掉一半隐藏神经元导致网络结构已经不同，整个dropout过程就相当于对很多个不同的神经网络取平均。而不同的网络产生不同的过拟合，一些互为“反向”的拟合相互抵消就可以达到整体上减少过拟合。
  * **（2）减少神经元之间复杂的共适应关系：** 因为dropout程序导致两个神经元不一定每次都在一个dropout网络中出现。这样权值的更新不再依赖于有固定关系的隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况 。迫使网络去学习更加鲁棒的特征 ，这些特征在其它的神经元的随机子集中也存在。换句话说假如我们的神经网络是在做出某种预测，它不应该对一些特定的线索片段太过敏感，即使丢失特定的线索，它也应该可以从众多其它线索中学习一些共同的特征。从这个角度看dropout就有点像L1，L2正则，减少权重使得网络对丢失特定神经元连接的鲁棒性提高。

 

31、  介绍各种优化方法，如 sgd，momentum，rmsprop，adam

* SGD: 每读入一条数据，就计算一次梯度，并更新权重$Θ=Θ−α⋅▽ΘJ(Θ;x(i),y(i))$

  Batch Gradient Descent; Mini-Batch Gradient Descent

  问题都是很难选择一个合理的学习率$α$

* momentum：$vt=γ⋅vt−1+α⋅▽ΘJ(Θ)$             $Θ=Θ−vt\Theta = \Theta-v_{t}$                  $Θ=Θ−vt$

  若当前梯度的方向与历史梯度一致（表明当前样本不太可能为异常点），则会增强这个方向的梯度，若当前梯度与历史梯方向不一致，则梯度会衰减

* rmsprop: rmsprop是adagrad的改进版，adagrad会对每个单独的权重$ Θi$改变其学习率，但是分母是历史梯度的平方和，容易造成衰减过快，rmsprop用的是历史梯度的均值，并且对Θ进行更新，不用分别用不同的学习率更新$ Θi$

* Adam：是momentum和rmsprop的结合，一方面梯度用滑动平均替代，另一方面学习率除以历史梯度的平方和，减缓学习率



32、  如果训练的神经网络不收敛，可能有哪些原因？

* 数据没有归一化

* 训练数据太大

* 学习率和优化函数选择

* 输出层选错激活函数（分类问题和回归问题区别）

* 神经元大量死亡，通常用Relu会遇到，改为leaky Relu

* 初始化权重错误

  

33、  如何理解卷积核，1*1 的卷积核有什么用？

* 卷积核的作用是提取图像更高维的特征

* 1*1卷积核不改变图像的宽高，只改变图像的维度（例如图像中的通道数）